{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "084a5836-46c8-47ac-a1e0-e8348a525150",
      "metadata": {
        "id": "084a5836-46c8-47ac-a1e0-e8348a525150"
      },
      "source": [
        "# ProgrammingAssignment06_clusterAnalysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7bf8149-9aa3-4627-8f2c-49e531f9c5e9",
      "metadata": {
        "id": "c7bf8149-9aa3-4627-8f2c-49e531f9c5e9"
      },
      "source": [
        "## 1. k-means using scikit-learn\n",
        "The healthy_lifestyle dataset contains information on lifestyle measures such as amount of sunshine, pollution, and happiness levels for 44 major cities around the world. Apply k-means clustering to the cities' number of hours of sunshine and happiness levels.\n",
        "\n",
        "- Import the needed packages for clustering.\n",
        "- Initialize and fit a k-means clustering model using sklearn's Kmeans() function.\n",
        "- Use the user-defined number of clusters, init='random', n_init=10, random_state=123, and algorithm='elkan'.\n",
        "- Find the cluster centroids and inertia.\n",
        "\n",
        "Ex: If the input is: 4\n",
        "\n",
        "the output should be:\n",
        "\n",
        "- Centroids: [[ 0.8294  0.2562]\n",
        " [ 1.3106 -1.887 ]\n",
        " [-0.9471  0.8281]\n",
        " [-0.6372 -0.7943]]\n",
        "- Inertia: 16.4991"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad54189b-81b1-4a58-9dd8-42ca5ba05310",
      "metadata": {
        "id": "ad54189b-81b1-4a58-9dd8-42ca5ba05310"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "healthy = pd.read_csv('healthy_lifestyle.csv')\n",
        "\n",
        "# Input the number of clusters\n",
        "number = int(input(\"Enter the number of clusters: \"))\n",
        "\n",
        "# Define input features\n",
        "X = healthy[['sunshine_hours', 'happiness_levels']]\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=['sunshine_hours', 'happiness_levels'])\n",
        "X_scaled = X_scaled.dropna()\n",
        "\n",
        "# Initialize and fit the k-means model\n",
        "kmeans = KMeans(n_clusters=number, init='random', n_init=10, random_state=123, algorithm='elkan')\n",
        "kmeans.fit(X_scaled)\n",
        "\n",
        "# Extract centroids and inertia\n",
        "centroids = kmeans.cluster_centers_\n",
        "inertia = kmeans.inertia_\n",
        "\n",
        "# Print the results\n",
        "print(\"Centroids:\", np.round(centroids, 4))\n",
        "print(\"Inertia:\", np.round(inertia, 4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18700cd6-8069-458a-8822-61f755fd893e",
      "metadata": {
        "id": "18700cd6-8069-458a-8822-61f755fd893e"
      },
      "source": [
        "## 2. Hierarchical clustering using scikit-learn\n",
        "The healthy_lifestyle dataset contains information on lifestyle measures such as amount of sunshine, pollution, and happiness levels for 44 major cities around the world. Apply agglomerative clustering to the cities' number of hours of sunshine and happiness levels using both sklearn and SciPy.\n",
        "\n",
        "- Import the needed packages for agglomerative clustering from sklearn and SciPy.\n",
        "- Initialize and fit an agglomerative clustering model using sklearn's AgglomerativeClustering() function. Use the user-defined number of clusters and ward linkage.\n",
        "- Add cluster labels to the input feature dataframe.\n",
        "- Calculate the distances between all instances using SciPy's pdist() function.\n",
        "- Convert the distance matrix to a square matrix using SciPy's squareform() function.\n",
        "- Define a clustering model with ward linkage using SciPy's linkage() function.\n",
        "\n",
        "Ex: If the input is: 4\n",
        "\n",
        "the output should be:\n",
        "|       | sunshine_hours | happiness_levels | labels |\n",
        "|-------|----------------|------------------|--------|\n",
        "| 0     | -0.691660      | 1.025642         | 3      |\n",
        "| 1     | 0.695725       | 0.801124         | 0      |\n",
        "| 2     | -0.645295      | 0.872562         | 3      |\n",
        "| 3     | -0.757641      | 0.933794         | 3      |\n",
        "| 4     | -1.098246      | 1.229750         | 3      |\n",
        "\n",
        "\n",
        "First five rows of the linkage matrix from SciPy:\n",
        "    \n",
        " - [[39. 40.  0.  2.]\n",
        " [28. 43.  0.  3.]\n",
        " [ 7. 18.  0.  2.]\n",
        " [ 8. 42.  0.  2.]\n",
        " [ 0.  3.  0.  2.]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f58d1471-d33e-43b5-839c-ba86c9509ebc",
      "metadata": {
        "id": "f58d1471-d33e-43b5-839c-ba86c9509ebc"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from scipy.cluster.hierarchy import linkage\n",
        "import warnings\n",
        "\n",
        "# Silence warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load dataset\n",
        "healthy = pd.read_csv('healthy_lifestyle.csv')\n",
        "\n",
        "# Input the number of clusters\n",
        "number = int(input(\"Enter the number of clusters: \"))\n",
        "\n",
        "# Define input features\n",
        "X = healthy[['sunshine_hours', 'happiness_levels']]\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=['sunshine_hours', 'happiness_levels'])\n",
        "X_scaled = X_scaled.dropna()\n",
        "\n",
        "# Initialize and fit agglomerative clustering model\n",
        "agglo = AgglomerativeClustering(n_clusters=number, linkage='ward')\n",
        "X_scaled['labels'] = agglo.fit_predict(X_scaled)\n",
        "\n",
        "# Display the clustered dataframe\n",
        "print(X_scaled.head())\n",
        "\n",
        "# Calculate distances and apply hierarchical linkage\n",
        "distance_matrix = pdist(X_scaled[['sunshine_hours', 'happiness_levels']])\n",
        "square_distance_matrix = squareform(distance_matrix)\n",
        "clusters_healthy_scipy = linkage(distance_matrix, method='ward')\n",
        "\n",
        "# Print first five rows of the linkage matrix\n",
        "print(\"First five rows of the linkage matrix from SciPy:\\n\", np.round(clusters_healthy_scipy[:5], 0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78db51dd-7ad3-4f58-b0ff-ae71a6c306e8",
      "metadata": {
        "id": "78db51dd-7ad3-4f58-b0ff-ae71a6c306e8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d92b04d3-05bd-470c-a199-327a6b55679c",
      "metadata": {
        "id": "d92b04d3-05bd-470c-a199-327a6b55679c"
      },
      "source": [
        "## 3. DBSCAN using scikit-learn\n",
        "- Increase the **number of points sampled to 500**.\n",
        "- Apply the DBSCAN model with **epsilon=1** and **min_samples=8** to identify the number of core-points and outliers (or noise).\n",
        "- EX: if the epsilon=1 and min_samples = 10 and number of points sampled to 100.\n",
        "  - the number of core-points = 85\n",
        "  - the number of outliers    = 11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdeae7b7-d4e7-483a-81bc-1d4bd4d6716c",
      "metadata": {
        "id": "fdeae7b7-d4e7-483a-81bc-1d4bd4d6716c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "# Load the full grocery customer dataset and take a random sample of 500 instances\n",
        "data = pd.read_csv('customer_personality.csv').sample( # your code here , random_state=123)\n",
        "\n",
        "# Use StandardScaler() to standardize input features\n",
        "X = data[['Fruits', 'Meats']]\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X = pd.DataFrame(X)\n",
        "\n",
        "# Apply DBSCAN with epsilon=1 and min_samples = 8\n",
        "dbscan = # Your code here\n",
        "dbscan = dbscan.fit(X)\n",
        "\n",
        "# Print the cluster labels and core point indices\n",
        "print('Labels:', # Your code here )\n",
        "print('Core points:', # Your code here )\n",
        "print('Number of core points:', # Your code here )\n",
        "\n",
        "# Add the cluster labels to the dataset as strings\n",
        "data['clusters'] = dbscan.labels_.astype(str)\n",
        "\n",
        "# Sort by cluster label (for plotting purposes)\n",
        "data.sort_values(by='clusters', inplace=True)\n",
        "\n",
        "# Plot clusters on the original data\n",
        "p = sns.scatterplot(data=data, x='Fruits',\n",
        "                    y='Meats', hue='clusters',\n",
        "                    style='clusters')\n",
        "p.set_xlabel('Fruits', fontsize=16)\n",
        "p.set_ylabel('Meats', fontsize=16)\n",
        "p.legend(title='DBSCAN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ea545b6-c934-42ca-9f5a-be7bf69d22d9",
      "metadata": {
        "id": "3ea545b6-c934-42ca-9f5a-be7bf69d22d9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}